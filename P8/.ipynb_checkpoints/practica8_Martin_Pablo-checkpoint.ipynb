{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_PRÁCTICA 8 - TAA_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pablo Martín de Benito_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk \n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = optical_recognition_of_handwritten_digits.data.features \n",
    "y = optical_recognition_of_handwritten_digits.data.targets \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rlm(object):\n",
    "    def __init__(self):\n",
    "        self.modelos = []\n",
    "        self.predicciones = []\n",
    "        self.probabilidades = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.nclases = np.unique(y).shape[0]        # No es un vector, es un número de clases\n",
    "        onehot = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "        # Obtenemos la salida deseado de cada clasificador individual\n",
    "        y_onehot = onehot.fit_transform(y.reshape(-1,1))     # El encoder exige que la entrada tenga dos dimensiones\n",
    "        print(\"\\nSalida Deseada:    \\n\",y_onehot)\n",
    "\n",
    "        for i in range(self.nclases):              # Se crea un objeto regresión para cada clase y se predice para cada una si es de esa clase o no\n",
    "            self.modelos.append(LinearRegression())\n",
    "            self.modelos[-1].fit(X,y_onehot[:,i])\n",
    "        \n",
    "    def predict(self,test):\n",
    "        predicciones_codificadas = []\n",
    "        \n",
    "        for modelo in self.modelos:\n",
    "            pred = modelo.predict(test)\n",
    "            self.predicciones.append(pred)\n",
    "        \n",
    "        self.predicciones = np.array(self.predicciones).T\n",
    "        \n",
    "        mat_pred = self.predicciones\n",
    "        for i in mat_pred:\n",
    "            pred_max = np.argmax(i)\n",
    "\n",
    "            pred_bin = np.zeros_like(i)\n",
    "            pred_bin[pred_max] = 1\n",
    "            predicciones_codificadas.append(pred_bin)\n",
    "        \n",
    "        predicciones_codificadas = np.array(predicciones_codificadas)\n",
    "        return(predicciones_codificadas)\n",
    "        \n",
    "    def predict_proba(self):\n",
    "        for elem in self.predicciones:\n",
    "            self.probabilidades.append(self.softmax(elem))\n",
    "        \n",
    "        return(np.array(self.probabilidades))\n",
    "\n",
    "    def score(self,X,y):\n",
    "        onehot = OneHotEncoder(sparse_output=False)\n",
    "        y_deseada = onehot.fit_transform(y.reshape(-1,1)) \n",
    "\n",
    "        self.predicciones = []\n",
    "        preds = self.predict(X)\n",
    "\n",
    "        # No utilizamos fit porque el fit lo haces con el entrenamiento y el score con el test\n",
    "        \n",
    "        return(accuracy_score(y_deseada,preds))\n",
    "\n",
    "\n",
    "    \n",
    "    def softmax(self,z):\n",
    "        z = z - np.max(z)  # Restar el máximo valor para evitar el desbordamiento numérico\n",
    "        exp_z = np.exp(z)   # Calcular el exponente de cada elemento en z\n",
    "        softmax_output = exp_z / np.sum(exp_z)  # Aplicar softmax\n",
    "        \n",
    "        return softmax_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba método fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "o = rlm()\n",
    "X_array = np.array(X)\n",
    "y_array = np.array(y)\n",
    "o.fit(X_array,y_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76386117,  1.07540944,  0.05982067, ...,  0.04871539,\n",
       "        0.26843784, -0.10737006])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.modelos[0].predict(X_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba método predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.predict(X_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba método predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1874531 , 0.07047201, 0.08566112, ..., 0.07907059, 0.09577188,\n",
       "        0.0962087 ],\n",
       "       [0.24576241, 0.06985995, 0.08556162, ..., 0.07810133, 0.08269697,\n",
       "        0.08684725],\n",
       "       [0.09066307, 0.0831911 , 0.09572556, ..., 0.22682851, 0.09115263,\n",
       "        0.07267071],\n",
       "       ...,\n",
       "       [0.09147612, 0.10740303, 0.08890767, ..., 0.07702298, 0.18388516,\n",
       "        0.08770021],\n",
       "       [0.11641502, 0.10648952, 0.09032758, ..., 0.08322797, 0.10007171,\n",
       "        0.15075447],\n",
       "       [0.0796674 , 0.08484972, 0.09268402, ..., 0.07996826, 0.14770502,\n",
       "        0.11290596]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382562277580071"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.score(X_array,y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método de Hold-Out sobre el conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9263214095034704"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out = rlm()\n",
    "\n",
    "X_train = X_array[0:3747,:]\n",
    "y_train = y_array[0:3747]\n",
    "\n",
    "X_test = X_array[3747:5620,:]\n",
    "y_test = y_array[3747:5620]\n",
    "\n",
    "hold_out.fit(X_train,y_train)\n",
    "hold_out.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación Cruzada dos particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0 : \n",
      "\n",
      "Salida Deseada:    \n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      "Función rlm: \n",
      "Score:    0.9261565836298933\n",
      "\n",
      "Regresión Logística sklearn:\n",
      "Score:    0.9519572953736655\n",
      "\n",
      "Fold  1 : \n",
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Función rlm: \n",
      "Score:    0.8905693950177936\n",
      "\n",
      "Regresión Logística sklearn:\n",
      "Score:    0.9457295373665481\n",
      "\n",
      "Fold  2 : \n",
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      "Función rlm: \n",
      "Score:    0.9279359430604982\n",
      "\n",
      "Regresión Logística sklearn:\n",
      "Score:    0.949288256227758\n",
      "\n",
      "Fold  3 : \n",
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      "Función rlm: \n",
      "Score:    0.9261565836298933\n",
      "\n",
      "Regresión Logística sklearn:\n",
      "Score:    0.9314946619217082\n",
      "\n",
      "Fold  4 : \n",
      "\n",
      "Salida Deseada:    \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      "Función rlm: \n",
      "Score:    0.9083629893238434\n",
      "\n",
      "Regresión Logística sklearn:\n",
      "Score:    0.9243772241992882\n",
      "\n",
      "Tasa de acierto media rlm:      0.9158362989323845\n",
      "\n",
      "Tasa de acierto media clf:      0.9405693950177936\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "scores_rlm = []\n",
    "scores_clf = []\n",
    "for i, (train_index,test_index) in enumerate(skf.split(X_array,y_array)):\n",
    "    print(\"\\nFold \",i,\": \")\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for elem_train, elem_test in zip(train_index,test_index):\n",
    "        X_train.append(X_array[elem_train,:])\n",
    "        y_train.append(y_array[elem_train])\n",
    "\n",
    "        X_test.append(X_array[elem_test,:])\n",
    "        y_test.append(y_array[elem_test])\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    reg = rlm()\n",
    "    clf = LogisticRegression(max_iter=10000)        \n",
    "\n",
    "    reg.fit(X_train,y_train)\n",
    "    clf.fit(X_train,y_train.reshape(-1))\n",
    "\n",
    "    print(\"\\nFunción rlm: \")\n",
    "    score_rlm = reg.score(X_test,y_test)\n",
    "    scores_rlm.append(score_rlm)\n",
    "    print(\"Score:   \",score_rlm)\n",
    "\n",
    "    print(\"\\nRegresión Logística sklearn:\")\n",
    "    score_clf = clf.score(X_test,y_test.reshape(-1))\n",
    "    scores_clf.append(score_clf)\n",
    "    print(\"Score:   \",score_clf)\n",
    "\n",
    "print(\"\\nTasa de acierto media rlm:     \",np.mean(scores_rlm))\n",
    "print(\"\\nTasa de acierto media clf:     \",np.mean(scores_clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
